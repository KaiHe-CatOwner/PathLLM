{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64966d45-34f8-46d8-a2c6-b0f63d44be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bask/projects/p/phwq4930-gbm/Zeyu/asiw9691_conda_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, AutoTokenizer, HfArgumentParser\n",
    "from utils.my_trainer import CustomTrainer\n",
    "from utils.utils import my_compute_metrics,seed_everything\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass, field\n",
    "from model.qformer import Blip2QformerPathInstruct\n",
    "from peft import LoraConfig\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from utils.data_collator import MyDataCollatorForQFormerPatchInstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1997c9fc-1703-4763-a3d6-bd03381d568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tokens_ids:  [128256, 128257, 128258]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "llm_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "# set up tokenizer\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "llm_tokenizer.padding_side = \"right\"\n",
    "llm_tokenizer.truncation_side = 'left'\n",
    "\n",
    "new_tokens = ['<Question>',  '<Answer>', '<Image>']  \n",
    "num_added_toks = llm_tokenizer.add_tokens(new_tokens)\n",
    "new_tokens_ids = llm_tokenizer.convert_tokens_to_ids(new_tokens)\n",
    "print(\"new_tokens_ids: \", new_tokens_ids)\n",
    "\n",
    "questions = pd.read_csv('./utils/question_list.csv', header=None)  \n",
    "questions = questions[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa2490c-49f8-4a48-bc41-9a8228b2076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func_ytb(examples):\n",
    "    text = examples['conversations'].replace(\"<image>\\n\", \"\").replace(\"<image>\", \"\")\n",
    "    question = ast.literal_eval(text[1:-1].split('\\n')[0])['value'].replace(\"\\n\", \"\")\n",
    "    answer = ast.literal_eval(text[1:-1].split('\\n')[1])['value'].replace(\"\\n\", \"\")\n",
    "    text = f\"<Question> {question}{llm_tokenizer.eos_token}\" # + f\"<Answer> {answer}{llm_tokenizer.eos_token}\\n\"\n",
    "    examples[\"text_input\"] = question\n",
    "    examples[\"text\"] = text\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09847db-dbb3-4b1b-bc42-85ea32b03f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset for wsi\n",
    "data_cache_dir = \"/bask/projects/p/phwq4930-gbm/Zeyu/PathVLM/.cache\"\n",
    "# select_data_num = 100\n",
    "# dataset_local_path = \"/home/shared/su123/YoutubePathQA/pretrain_data_all\"\n",
    "# split_text = \"train[:{}]\".format(select_data_num) # [:10000]\n",
    "\n",
    "# dataset = load_from_disk(dataset_local_path)\n",
    "# dataset = dataset.map(formatting_func_ytb, num_proc=4, remove_columns=['id','conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f552f05-7646-4a2a-92df-97ce29cb42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a278b6-28cc-4aee-a4a4-4f435614b7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision_encoder loading ...\n",
      "llm loading ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:47<00:00, 11.78s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Blip2QformerPathInstruct(\n",
    "                                    clip_name = 'conch',\n",
    "                                    num_query_token = 16,\n",
    "                                    cross_attention_freq = 2,\n",
    "                                    pretrain_name = 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
    "                                    llm_requires_grad = False, \n",
    "                                    load_in_8bit = False, \n",
    "                                    load_in_4bit = False, \n",
    "                                    llm_name = llm_name, \n",
    "                                    trust_remote_code = False, \n",
    "                                    token = None, \n",
    "                                    llm_tokenizer = llm_tokenizer,\n",
    "                                    image_token_id = new_tokens_ids[-1],\n",
    "                                    data_cache_dir = data_cache_dir,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb9cf3a-74da-4e4d-952d-a0ab286e023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2QformerPathInstruct(\n",
       "  (vision_encoder): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (Qformer): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (llm): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128259, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128259, bias=False)\n",
       "  )\n",
       "  (embedding_layer): Embedding(128259, 4096)\n",
       "  (resampler_layer): Sequential(\n",
       "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=768, out_features=4096, bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = \"/bask/homes/a/asiw9691/PathVLM/source/PathLLM/output/Conch_Bert_Llama3_PatchInstruct/ckpt500.bin\"\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=False)\n",
    "model.to(device)\n",
    "# model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a828f06-78ca-4d76-abbc-e855a70fb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4  # 你可以根据需要调整批处理大小\n",
    "\n",
    "data_collator = MyDataCollatorForQFormerPatchInstruct(image_processor=model.image_processor, tokenizer=llm_tokenizer, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f45a30-f1ed-44dd-a581-ccd6ab9b9cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4ea27e7ad241b0a1e09548bfc2a01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "            llm_tokenizer,\n",
    "            batched=False,\n",
    "            # remove_columns=['text'],\n",
    "            num_proc=10,\n",
    "            batch_size=batch_size,\n",
    "            input_columns=['text'],\n",
    "       )\n",
    "\n",
    "dataloader_params = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"collate_fn\": data_collator,\n",
    "        }\n",
    "\n",
    "eval_dataloader = DataLoader(tokenized_dataset, **dataloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a04cacd0-e70c-465a-a3f2-0d91b96c173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "                max_length=512,\n",
    "                temperature=1.0,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                num_return_sequences=1,\n",
    "                repetition_penalty=1.1,\n",
    "                do_sample=True,\n",
    "                pad_token_id=llm_tokenizer.eos_token_id,\n",
    "                bos_token_id=llm_tokenizer.bos_token_id,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f59927b-bfdb-4ec7-bc2f-723dfc644aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in tqdm(eval_dataloader):\n",
    "eval_data_iter = iter(eval_dataloader)\n",
    "batch = next(eval_data_iter)\n",
    "input_ids = batch['input_ids'].to(device)\n",
    "attention_masks = batch['attention_mask'].to(device)\n",
    "image = batch['image'].to(device)\n",
    "text = batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89bb0e4b-1a4e-4568-abe0-92d2399a0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaaca4-b382-4c64-9885-45827ddad142",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    llm_input_ids = batch[\"input_ids\"].to(device)\n",
    "    image = batch[\"image\"].to(device).to(torch.bfloat16)\n",
    "    llm_input_attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    p_num = batch[\"patch_num\"]\n",
    "\n",
    "    image_embeds = model.vision_encoder.encode_image(image, normalize=False, proj_contrast=False)\n",
    "    image_embeds, image_atts = model._split_and_pad(image_embeds, p_num)\n",
    "\n",
    "    image_embeds = image_embeds.to(image.device).to(torch.bfloat16) # batch x max_length x 512\n",
    "    image_atts = image_atts.to(image.device) # batch x max_length\n",
    "\n",
    "    query_tokens = model.query_tokens.expand(image_embeds.shape[0], -1, -1).to(torch.bfloat16) # learnable query\n",
    "    \n",
    "    text_Qformer = model.bert_tokenizer(\n",
    "                        text,\n",
    "                        padding='longest',\n",
    "                        truncation=True,\n",
    "                        max_length=model.max_txt_len,\n",
    "                        return_tensors=\"pt\",\n",
    "                    ).to(image.device)\n",
    "    \n",
    "    query_atts = torch.ones(query_tokens.size()[:-1]).to(image.device)\n",
    "    Qformer_atts = torch.cat([query_atts, text_Qformer.attention_mask],dim=1)\n",
    "\n",
    "    query_output = model.Qformer.bert(\n",
    "                        text_Qformer.input_ids,\n",
    "                        attention_mask=Qformer_atts,\n",
    "                        query_embeds=query_tokens,\n",
    "                        encoder_hidden_states=image_embeds,\n",
    "                        encoder_attention_mask=image_atts,\n",
    "                        return_dict=True,\n",
    "                    )\n",
    "\n",
    "    llm_query_input = model.resampler_layer(query_output.last_hidden_state[:,:query_tokens.size(1),:])\n",
    "\n",
    "    fusion_embs = model.get_fusion_embedding(llm_input_ids, llm_query_input)\n",
    "\n",
    "    fusion_attention_mask = model.pad_attention_fusion(fusion_embs.size(1), llm_input_attention_mask)\n",
    "    \n",
    "    res = model.llm.generate(inputs_embeds=fusion_embs, attention_mask=fusion_attention_mask, generation_config=generation_config)\n",
    "\n",
    "generate_list = []\n",
    "for item in res:\n",
    "    generation = model.llm_tokenizer.decode(item, skip_special_tokens=True)\n",
    "    generate_list.append(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1968e286-2dbc-4997-8bbf-f5d9b619a7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624/624 [18:31<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于每个批次的数据\n",
    "import numpy as np\n",
    "from utils.eval_utils import calculate_f1score \n",
    "from tqdm import tqdm\n",
    "\n",
    "close_ques_acc = 0\n",
    "close_ques_num = 0\n",
    "open_ques_f1 = []\n",
    "\n",
    "open_candidate = []\n",
    "open_reference = []\n",
    "\n",
    "close_candidate = []\n",
    "close_reference = []\n",
    "\n",
    "max_seq = 0\n",
    "\n",
    "for batch in tqdm(eval_dataloader):\n",
    "# eval_data_iter = iter(eval_dataloader)\n",
    "# batch = next(eval_data_iter)\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_masks = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    fea1 = batch['fea1'].to(device)\n",
    "    fea2 = batch['fea2'].to(device)\n",
    "    fea3 = batch['fea3'].to(device)\n",
    "    mask1 = batch['mask1'].to(device)\n",
    "    mask2 = batch['mask2'].to(device)\n",
    "    mask3 = batch['mask3'].to(device)\n",
    "    answers = batch['answers']\n",
    "    if fea1.shape[1] > max_seq:\n",
    "        max_seq = fea1.shape[1]\n",
    "\n",
    "print(max_seq)\n",
    "#     break\n",
    "#     # 执行模型推断\n",
    "#     res = model.generate(input_ids=input_ids,\n",
    "#                          attention_mask=attention_masks,\n",
    "#                          fea1 = fea1,\n",
    "#                          fea2 = fea2,\n",
    "#                          fea3 = fea3,\n",
    "#                          mask1 = mask1,\n",
    "#                          mask2 = mask2,\n",
    "#                          mask3 = mask3,\n",
    "#                         )\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     for i in range(len(answers)):\n",
    "#         if answers[i] in ['yes','no']:\n",
    "#             close_candidate.append(res[i])\n",
    "#             close_reference.append(answers[i])\n",
    "#         else:\n",
    "#             open_candidate.append(res[i])\n",
    "#             open_reference.append(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f10888c-c8be-4257-8e2d-dbbefbd6451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.generate(input_ids=input_ids,\n",
    "                     attention_mask=attention_masks,\n",
    "                     fea1 = fea1,\n",
    "                     fea2 = fea2,\n",
    "                     fea3 = fea3,\n",
    "                     mask1 = mask1,\n",
    "                     mask2 = mask2,\n",
    "                     mask3 = mask3,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b77e9e59-0a20-4dea-874d-f3e372b6f46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The primary diagnosis is transitional cell carcinoma originating from the bladder. Histological examination of the H&E stained WSI from the tumor center reveals a diffusely distributed cell pattern with mosaic and streaming necrosis, alongside stellate-form lymphocytic infiltration. Fibrosis and myxoid changes are present. Cellular features include spindle cell proliferation, scattered pleomorphism with lipoblasts, and inflammatory cells. There is variable cytologic atypia with hyperchromatic and multinucleated giant cells, and notable mitotic activity, contributing to a nuclear grade assessment of G2. The histological diagnosis is urothelial carcinoma G2. Recommended related IHC tests include CK7, CK20, and GATA3 to further characterize the tumor.',\n",
       " 'The original site of the tumor is the lateral wall of the bladder, diagnosed as high-grade urothelial carcinoma, specifically transitional cell carcinoma. The cancer is staged at AJCC/UICC pT3aN0MX. Microscopic examination of the H&E-stained whole slide image from the tumor center reveals high-grade urothelial carcinoma involving the perivesicular tissue, with carcinoma in situ present within the epithelial abnormalities of the bladder. There is no evidence of lymphatic or vascular invasion. The prostate and seminal vesicles show no significant pathologic abnormalities. Given the diagnosis, related immunohistochemistry (IHC) tests such as CK7, CK20, and GATA3 may be recommended to further characterize the tumor.',\n",
       " 'The primary diagnosis is transitional cell carcinoma, originating from the bladder. The specific subtype is urothelial carcinoma, classified as PT2b, indicating invasion into the muscular propria without lymphatic vessel invasion. The H&E stained whole slide image (WSI) from the tumor center shows urothelial carcinoma with tumor infiltration at the margins. The tumor is located at the apex of the bladder and measures 3.5 cm in diameter. No carcinoma is observed in the distal ureters, fallopian tubes, or left pelvic lymph nodes. The presence of carcinoma is confirmed in three lymph nodes. The tumor does not invade the lymphatic vessels, and there is no carcinoma at the resection margins. For further characterization, related immunohistochemistry (IHC) tests such as GATA3, CK7, CK20, and p63 are recommended.',\n",
       " 'The primary diagnosis is transitional cell carcinoma originating from the bladder, specifically identified as urothelial carcinoma with nested features. The cancer is high-grade (grade 3) and exhibits extensive invasion into the muscularis propria, with a suspicion of lymphovascular invasion. The H&E stained whole slide image (WSI) from the tumor center shows ulceration, necrosis, inflammation, and reactive stromal cells suggestive of prior resection changes. For further evaluation, related immunohistochemistry (IHC) tests are recommended.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee5689e-e3a7-4056-8283-9063461d7bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The primary diagnosis is transitional cell carcinoma originating from the bladder. Histopathological examination of the tumor center reveals a Grade 3 poorly differentiated transitional cell carcinoma with invasion into perivesical adipose tissue, extensively infiltrating the right and left perivesicles. The carcinoma also invades the trigone and periurethral prostatic ducts. Focal dystrophic calcification is noted within the tumor. No angiolymphatic or perineural invasion is identified. The tumor is staged as T3a N0 Mx. It is recommended to perform immunohistochemistry tests for markers such as CK7, CK20, p63, GATA3, and uroplakin to further characterize the tumor. Additionally, related IHC tests that may be beneficial include PSA (Prostate-Specific Antigen) and PSAP (Prostatic Acid Phosphatase) due to the involvement of prostatic structures. Recommend related IHC tests',\n",
       " ' The pathology report describes a case of invasive urothelial carcinoma originating from the anterior wall of the bladder. This high-grade transitional cell carcinoma invades through the muscularis propria and into perivesical fat, demonstrating extensive local invasion. The tumor is multifocal with involvement of the prostate. The pathologic stage for the bladder is pT3b N2 Mx and for the prostate, it is pT2c N0 Mx. No vascular or lymphatic invasion is identified. The surgical margins are clear. Other findings include chronic cystitis and benign mucinous glands in the cervix and serosa of the uterus. It is recommended to perform immunohistochemistry (IHC) tests to further characterize the urothelial carcinoma. Related IHC tests such as GATA3, CK20, and p63 could be beneficial for this purpose. Additionally, consider performing IHC tests for therapeutic decision-making. For instance, if',\n",
       " ' The primary diagnosis is transitional cell carcinoma originating from the bladder. The cancer type is invasive urothelial carcinoma, which is high-grade and moderately differentiated. The stage is pT3a Nx Mx according to AJCC (7th edition). H&E stained whole slide images (WSI) from the tumor center reveal invasive high-grade urothelial carcinoma infiltrating the detrusor muscle and extending into the perivesicular fat with lymphatic invasion. Multifocal non-invasive urothelial carcinoma and urothelial dysplasia are also present. For further evaluation, it is recommended to perform immunohistochemistry tests for markers such as GATA3, CK20, and p63 to confirm urothelial origin and assess differentiation status. Additionally, related IHC tests that may be recommended include Ki-67 to evaluate proliferative activity and HPV to rule out association with human papillomavirus infection. Relevant descriptions',\n",
       " \" The pathology report describes a bladder tumor specimen diagnosed as transitional cell carcinoma, grade 3. The primary site is the bladder, and the cancer type is transitional cell carcinoma with a specific subtype of high-grade urothelial carcinoma, grades 2-3. The tumor has invaded the muscularis propria without lymphovascular invasion or radiation reaction. Pathologic staging indicates a pT2b stage. Microscopic examination confirms the presence of high-grade urothelial carcinoma within the bladder tissue. For further evaluation, related immunohistochemistry (IHC) tests such as GATA3, CK20, and uroplakin may be recommended. Consultation with a healthcare provider is advised for appropriate management and follow-up. Recommended related IHC tests include GATA3, CK20, and uroplakin. The patient's medical history includes prior prostate cancer treated with radiation. Relevant social history includes age and sex. Further clinical correlation and\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047dee94-0c2c-4d24-8ff5-987d30adc2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.27001985016993246, 'p': 0.017507060508135417, 'f': 0.03129752911526289}, 'rouge-2': {'r': 0.05284908234126984, 'p': 0.0023333627239040663, 'f': 0.004323536432612713}, 'rouge-l': {'r': 0.2615928062936698, 'p': 0.016450324600026073, 'f': 0.02950558446856401}}\n",
      "0.04000689721539458\n",
      "0.9538043478260869\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "open_ques_rouge = []\n",
    "\n",
    "for i in range(len(close_reference)):\n",
    "    close_ques_num += 1\n",
    "    if close_reference[i] in close_candidate[i]:\n",
    "        close_ques_acc += 1\n",
    "        \n",
    "for i in range(len(open_reference)):\n",
    "    f1_score = calculate_f1score(open_candidate[i], open_reference[i])\n",
    "    open_ques_f1.append(f1_score)\n",
    "    \n",
    "open_ques_rouge = rouge.get_scores(open_candidate, open_reference, avg=True) \n",
    "open_ques_f1 = np.mean(open_ques_f1)\n",
    "close_ques_acc = close_ques_acc/close_ques_num\n",
    "\n",
    "print(open_ques_rouge)\n",
    "print(open_ques_f1)\n",
    "print(close_ques_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "705d0d5a-544d-4b4d-b43d-6a6ed3bb1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = compute_bleu_scores(open_candidate, open_reference, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20d3c3df-2f49-42c4-885c-c5519ca310d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23677331586807712"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b631910-4d7e-41f7-83ca-9e37f6162712",
   "metadata": {},
   "source": [
    "### For one image QA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddcff2d8-2e18-4de4-be22-2cfb5aa50ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "question = \"What is your final diagnosis?\"\n",
    "text = f\"<Question> {question}{tokenizer.eos_token}\"\n",
    "image = Image.open(\"./test_images/test1.jpeg\")\n",
    "\n",
    "# i = 1\n",
    "# text = dataset[i]['text']\n",
    "# image = dataset[i]['image']\n",
    "# answer = dataset[i]['answer']\n",
    "\n",
    "input_dic = tokenizer(text, return_tensors=\"pt\")\n",
    "map_image_data = model.image_processor(image)\n",
    "input_dic[\"image\"] = map_image_data\n",
    "\n",
    "res = model.generate(input_ids = input_dic[\"input_ids\"].to(device),\n",
    "                    attention_mask = input_dic[\"attention_mask\"].to(device),\n",
    "                    labels = input_dic[\"input_ids\"].to(device),\n",
    "                    image = input_dic[\"image\"].unsqueeze(0).to(device),\n",
    "                    temperature = 0.7,\n",
    "                    top_p = 0.9,\n",
    "                    num_return_sequences = 3,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5342222b-11a3-442b-b55d-bd7e2078647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import ImageFile, Image\n",
    "test_image_dir = \"./test_images/*\"\n",
    "\n",
    "image_paths = glob(test_image_dir)\n",
    "\n",
    "patch_list = []\n",
    "num_list = []\n",
    "text_list = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    image = data_collator._resize_image(image)\n",
    "    patches = data_collator._crop_image(image) # [448x448]\n",
    "    patches = [model.image_processor(patch) for patch in patches]\n",
    "    num_list.append(len(patches))\n",
    "    patch_list += patches\n",
    "    text_list.append(f\"<Question> What is the final pathological diagnosis for this image?{llm_tokenizer.eos_token}\")\n",
    "\n",
    "patch_list = torch.stack(patch_list) # [448x448]\n",
    "\n",
    "input_dic = llm_tokenizer(text_list, return_tensors=\"pt\")\n",
    "input_dic[\"image\"] = patch_list\n",
    "input_dic[\"patch_num\"] = num_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d841efad-3275-47f9-a21d-902571aadefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    llm_input_ids = input_dic[\"input_ids\"].to(device)\n",
    "    image = input_dic[\"image\"].to(device).to(torch.bfloat16)\n",
    "    llm_input_attention_mask = input_dic[\"attention_mask\"].to(device)\n",
    "    p_num = input_dic[\"patch_num\"]\n",
    "\n",
    "    image_embeds = model.vision_encoder.encode_image(image, normalize=False, proj_contrast=False)\n",
    "    image_embeds, image_atts = model._split_and_pad(image_embeds, p_num)\n",
    "\n",
    "    image_embeds = image_embeds.to(image.device).to(torch.bfloat16) # batch x max_length x 512\n",
    "    image_atts = image_atts.to(image.device) # batch x max_length\n",
    "\n",
    "    query_tokens = model.query_tokens.expand(image_embeds.shape[0], -1, -1).to(torch.bfloat16) # learnable query\n",
    "    \n",
    "    text_Qformer = model.bert_tokenizer(\n",
    "                        text_list,\n",
    "                        padding='longest',\n",
    "                        truncation=True,\n",
    "                        max_length=model.max_txt_len,\n",
    "                        return_tensors=\"pt\",\n",
    "                    ).to(image.device)\n",
    "    \n",
    "    query_atts = torch.ones(query_tokens.size()[:-1]).to(image.device)\n",
    "    Qformer_atts = torch.cat([query_atts, text_Qformer.attention_mask],dim=1)\n",
    "\n",
    "    query_output = model.Qformer.bert(\n",
    "                        text_Qformer.input_ids,\n",
    "                        attention_mask=Qformer_atts,\n",
    "                        query_embeds=query_tokens,\n",
    "                        encoder_hidden_states=image_embeds,\n",
    "                        encoder_attention_mask=image_atts,\n",
    "                        return_dict=True,\n",
    "                    )\n",
    "\n",
    "    llm_query_input = model.resampler_layer(query_output.last_hidden_state[:,:query_tokens.size(1),:])\n",
    "\n",
    "    fusion_embs = model.get_fusion_embedding(llm_input_ids, llm_query_input)\n",
    "\n",
    "    fusion_attention_mask = model.pad_attention_fusion(fusion_embs.size(1), llm_input_attention_mask)\n",
    "    \n",
    "    res = model.llm.generate(inputs_embeds=fusion_embs, attention_mask=fusion_attention_mask, generation_config=generation_config)\n",
    "\n",
    "generate_list = []\n",
    "for item in res:\n",
    "    generation = model.llm_tokenizer.decode(item, skip_special_tokens=True)\n",
    "    generate_list.append(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c43661fe-22e4-499f-91a3-eedfecddc99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test_images/test4.jpeg',\n",
       " './test_images/test1.jpeg',\n",
       " './test_images/test2.jpeg',\n",
       " './test_images/test3.jpeg']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b7748c2-296d-4143-a4b2-3277cb1e0a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<Answer> The final diagnosis is metaplastic meningothelial hyperplasia. The nuclear changes observed can be seen in a variety of conditions and must always be interpreted in the context of the overall histological pattern. The presence of ghost nuclei may suggest some form of cellular degeneration or pathology. However, this interpretation must also be carefully considered in the context of the entire histopathological examination. The absence of an atypia and mitotic activity further supports the likelihood that these are normal cells under stress rather than indicative of a malignant transformation. Further immunohistochemical studies can provide additional context and aid in confirming this preliminary interpretation. This image is a good example to highlight the importance of considering the entire histopathological context when interpreting these findings. It underscores the value of additional stains and other forms of ancillary testing in confirming these preliminary observations. This comprehensive approach ensures a more accurate and reliable diagnosis. It's crucial not to make sweeping deductions based solely on a single patch. A thorough analysis of the whole slide images is standard procedure to confirm any initial observations and establish a definitive diagnosis. This is particularly important in cases like this where the nuclear changes are quite prominent and potentially suggestive of various pathological conditions. The final diagnosis should reflect the full extent of the observations from the whole slide. In conclusion, this case serves as another reminder of the importance of a comprehensive review of the whole slide images and consideration of additional tests to confirm any initial interpretations. This approach is vital for establishing an accurate diagnosis and guiding patient management. It's also crucial to avoid premature conclusions based on a single patch analysis to ensure a thorough and reliable diagnostic process. The overall impression left by this case is one that emphasizes the value of a comprehensive review and correlation with clinical information and possibly additional ancillary studies. This comprehensive approach ensures a definitive and reliable diagnosis. It's crucial not to make sweeping deductions based solely on a single patch. A thorough analysis of the whole slide images is standard procedure to confirm any initial observations and establish a definitive diagnosis. This is particularly important in cases like this where the nuclear changes are quite prominent and potentially suggestive of various pathological conditions. The final diagnosis should reflect the full extent of the observations from the whole slide. In conclusion, this case serves as another reminder of the importance of a comprehensive review of the whole slide images and consideration of additional tests to confirm any initial interpretations. This approach is vital for establishing an accurate diagnosis and\",\n",
       " \"<Answer> The final diagnosis is Chromophobe renal cell cystadenoma. A chromophobe aspect can be helpful to exclude more solid or cellular tumors. However, the distinction between a tubulopapillary and a purely tubular appearance is somewhat subtle and may vary among observers. As mentioned earlier, the cytology of this image was fairly similar to the one shown in previous cases, including the case that led us to propose this entity. This suggests a degree of heterogeneity within this entity, which may be related to varying degrees of papillarity. The uniformity in cytology among cases is also relatively high. Given the overall architecture, nuclear morphology, and distribution of cells, it's unlikely that this entity would pose significant diagnostic challenges for most renal pathologists. Therefore, while a few exceptions may exist, a chromophobe renal cell cystadenoma would usually be an unambiguous diagnosis. The rest of the pathological image reveals similar features to what's depicted above. However, there are additional areas that were not included in the original patch but show consistent features with the diagnosis. Please note that if there are any inconsistencies or atypical features in other areas, they should be taken into account when making a definitive diagnosis. Histopathological diagnosis often requires a comprehensive evaluation of the entire slide rather than relying solely on the findings from a single patch. Additionally, correlation with clinical information, such as patient demographics and laboratory findings, can provide valuable context for interpreting these histopathological observations. Remember to consider all aspects of the case when formulating a diagnosis and management plan. This comprehensive approach ensures a thorough and accurate assessment of the patient's condition. Histopathologic features in this particular case did not present any unusual characteristics that warranted further investigation. If there are any atypical features in this case or others that raise suspicion for malignancy, consider consultation with a colleague or additional workup for confirmation. The lack of atypia here makes our conclusion regarding a benign process generally reliable. However, without considering atypical cases, a potentially malignant diagnosis may have been overlooked. Therefore, periodic review and revision of differential diagnoses are crucial. The bottom line is: even though these entities do not typically pose significant diagnostic challenges, ongoing evaluation and refinement are necessary for optimal patient care. The combination of architectural and cytologic features strongly suggests a benign tumor, which is characteristic of the entity we've studied. It's worth noting that\",\n",
       " '<Answer> The final diagnosis is an oncocytoma. Pathognomonic nuclear grooves are observed in the background of fine fibrous tissues with abundant eosinophilic cytoplasm. These cytologic features can provide a clue to support the preliminary diagnosis when obtained from a cytologic specimen. However, it may not be sufficient for definitive diagnosis and further pathological examination may be necessary. The final diagnosis should be based on a combination of pathognonomic histopathological features and additional diagnostic tests. 3+ is assigned for this image based on the overall quality of the images. It is recommended that a comprehensive assessment be conducted for each slide to ensure all relevant pathological features are considered. This will involve looking for pathognomorphic nuclear features consistent with the primary differential diagnosis, examining the background tissue architecture, and considering additional differential diagnoses. The final score should reflect the degree to which these considerations are taken into account. A high score would indicate a comprehensive and thorough approach to analysis. Please note that the scores are not intended to provide an overall performance indicator, but rather to guide the comprehensive assessment of each individual pathology image. This will lead to a more reliable and defensible pathological report. In conclusion, a score of 3 indicates a comprehensive approach to pathological assessment. This is consistent with the principles of good pathology practices where pathologists consider all relevant features when formulating their differential diagnosis and final diagnosis. Moving forward, there is a need to develop new digital tools and methods to promote and facilitate this type of comprehensive assessment. This will enhance the overall quality of pathological reports and the reliability of final diagnoses. This article was previously published with incorrect information. The current version of the scoring scale was introduced in 2014 during the EUPhAR conference, replacing the previous grading system. The grades range from 0 to 5, with higher scores indicating greater emphasis on pathognomorphism. Additional information can be found at the corresponding EUSM website or by contacting us directly. The correct final scores are: 2 and 2, respectively. However, the score has been adjusted in the present context to 3 and 3, as mentioned above. This difference in scores represents differences in the level of detail provided in the two cases presented. No additional information or resources were used to make this judgment. The interpretation of the scores is a matter of ongoing debate within the pathology community. Some colleagues feel that a',\n",
       " '<Answer> The final diagnosis is a moderately differentiated mucinous tumor with nuclear stratification and mild cytological atypia. There is no evidence of glandular crowding or necrosis, but the surface epithelium may show dysplastic change. Mitoses are uncommon. In this particular case, there is evidence of peritoneal invasion (pT2a). Prolactinoma: Pitfalls in pathogenesis can be overlooked. Immunoreactivity in tumor cells must be interpreted in the context of overall histopathological findings. H&E, 400x, Hematoxylin & Eosin staining. The cystic spaces contain anucleate cells with abundant, granular eosinophilic cytoplasm that has undergone metachromatic degeneration to purple. The nuclei have indistinct nucleoli and coarse, clumped chromatin. A peripheral rimming of cells can be seen at the periphery. At the time of original diagnosis, it was thought to be adenoid cystic carcinoma. However, subsequent re-excision and analysis revealed myoepithelial hyperplasia. Pathognomonic of pilocytic astrocytoma (PA) include eosinophilic bodies. These are round to oval clear spaces within the cytoplasm of tumor cells. They represent a form of cell injury caused by denervation of neurons, such as when tumor cells encase or invade neurons. The presence of these bodies within the tumor cell is one of the factors that help distinguish PA from other glial tumors. Therefore, their identification is crucial for making a definitive diagnosis. While they can sometimes undergo breakage during processing and fixation, they generally maintain their integrity due to cross-linking of intermediate filament cytoskeletons. The image shows PA with no malignant features. Hematoxylin & Eosin staining. Peritoneal invasion, pT2a; Tumor invasion of muscularis propria / detrusor muscle fibers. Hematoxylin & Eosin stain. A pitfall in the pathogenesis of prolactinomas is the misinterpretation of the presence of immunoreactivity in tumor cells for PRL as indicating tumoral secretion and function. This pitfall can be avoided by considering the possibility of stromal reactivity or cross-reactivity with IHC markers. In conclusion, while IHC studies can be valuable tools in the diagnostic process']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa75895-8cb3-44cb-8b4f-bfc7a305f537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2799affa-cf80-44c5-a07b-d179f15ee122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 13 11:51:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              55W / 400W |  40338MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2369704      C   .../Zeyu/asiw9691_conda_env/bin/python    40328MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22e875-3d49-43bc-a3b5-2606563636c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asiw9691_conda_env (Conda)",
   "language": "python",
   "name": "sys_asiw9691_conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
