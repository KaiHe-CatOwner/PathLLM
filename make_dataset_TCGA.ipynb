{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f29c83-d585-426b-843a-bff1a37ac449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b188064d-e5e5-4f1d-b996-5a0062a387a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your file dir path\n",
    "npy_directory = '/bask/projects/p/phwq4930-renal-canc/Zeyu/WSI_Dataset/Conch/TCGA-*/'\n",
    "txt_directory = '/bask/projects/p/phwq4930-renal-canc/Zeyu/WSI_Dataset/TCGA_Report/TXT-GPT4o'\n",
    "patients_file = '/bask/projects/p/phwq4930-renal-canc/Zeyu/WSI_Dataset/TCGA_Clinical.tsv'\n",
    "patients_list = pd.read_csv(patients_file, sep='\\t')[['case_submitter_id','project_id']].drop_duplicates()\n",
    "patients_list.columns = ['patient_id','project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5e93d83-97a5-44ee-a319-b8a1060cffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1_files = glob.glob(os.path.join(npy_directory, \"*_0_1024.npy\"))\n",
    "feature2_files = glob.glob(os.path.join(npy_directory, \"*_1_512.npy\"))\n",
    "feature3_files = glob.glob(os.path.join(npy_directory, \"*_1_1024.npy\"))\n",
    "text_files = glob.glob(os.path.join(txt_directory, \"*.txt\"))\n",
    "df_fea1 = pd.DataFrame(feature1_files, columns=['fea1_file_path'])\n",
    "df_fea2 = pd.DataFrame(feature2_files, columns=['fea2_file_path'])\n",
    "df_fea3 = pd.DataFrame(feature3_files, columns=['fea3_file_path'])\n",
    "df_text = pd.DataFrame(text_files, columns=['text_file_path'])\n",
    "df_fea1['slide_id'] = df_fea1['fea1_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "df_fea2['slide_id'] = df_fea2['fea2_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "df_fea3['slide_id'] = df_fea3['fea3_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a422e8ce-0512-4bbc-91d1-b58c10092131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fea1['slide_id'] = df_fea1['fea1_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "df_fea2['slide_id'] = df_fea2['fea2_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "df_fea3['slide_id'] = df_fea3['fea3_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "\n",
    "df_fea1 = df_fea1.drop_duplicates(subset='slide_id', keep='first').reset_index(drop=True)\n",
    "df_fea2 = df_fea2.drop_duplicates(subset='slide_id', keep='first').reset_index(drop=True)\n",
    "df_fea3 = df_fea3.drop_duplicates(subset='slide_id', keep='first').reset_index(drop=True)\n",
    "\n",
    "df_fea = pd.merge(df_fea1, df_fea2, on='slide_id', how='inner')\n",
    "df_fea = pd.merge(df_fea, df_fea3, on='slide_id', how='inner')\n",
    "\n",
    "df_fea['patient_id'] = df_fea['slide_id'].apply(lambda x: x[:12])\n",
    "\n",
    "df_text['patient_id'] = df_text['text_file_path'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "\n",
    "df = pd.merge(df_fea, df_text, on='patient_id', how='inner')\n",
    "\n",
    "df = pd.merge(df, patients_list, on='patient_id', how='inner')\n",
    "\n",
    "# df['project_old'] = df['fea1_file_path'].apply(lambda x: x.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbaa7c7b-a71d-46d9-927f-ab5f24bdc38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11664/11664 [00:19<00:00, 591.43it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "#     feature1_content = np.load(df.iloc[i]['fea1_file_path'], allow_pickle=True) \n",
    "#     feature1 = feature1_content[()]['feature'].cpu().numpy().flatten() # Nx512\n",
    "#     feature1_cor = np.array([x.split('_')[:2] for x in feature1_content[()]['index']]).astype('int').flatten() # Nx2\n",
    "    \n",
    "#     feature2_content = np.load(df.iloc[i]['fea2_file_path'], allow_pickle=True)\n",
    "#     feature2 = feature2_content[()]['feature'].cpu().numpy().flatten()\n",
    "#     feature2_cor = np.array([x.split('_')[:2] for x in feature2_content[()]['index']]).astype('int').flatten()\n",
    "    \n",
    "#     feature3_content = np.load(df.iloc[i]['fea3_file_path'], allow_pickle=True)\n",
    "#     feature3 = feature3_content[()]['feature'].cpu().numpy().flatten()\n",
    "#     feature3_cor = np.array([x.split('_')[:2] for x in feature3_content[()]['index']]).astype('int').flatten()\n",
    "    with open(df.iloc[i]['text_file_path'], 'r') as txt_file:\n",
    "        txt_content = txt_file.read()\n",
    "        \n",
    "    data.append({'f1024': df.iloc[i]['fea1_file_path'], \n",
    "                 'f2048': df.iloc[i]['fea2_file_path'], \n",
    "                 'f4096': df.iloc[i]['fea3_file_path'],\n",
    "                 'slide_id': df['slide_id'].iloc[i],\n",
    "                 'project': df['project'].iloc[i],\n",
    "                 'description': txt_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6266fec6-577d-4a3e-96ff-2da6d4ad5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to huggingface format\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5e1015d-0664-4e53-8156-7088baeb2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4af6b5f-bf38-4564-8113-7cbcc28cb18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 12/12 [00:00<00:00, 183.65ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CNX-PathLLM/TCGA-WSI-Description/commit/3943c12f76614c8e41004404e37f2b21c95b249c', commit_message='Upload dataset', commit_description='', oid='3943c12f76614c8e41004404e37f2b21c95b249c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub('CNX-PathLLM/TCGA-WSI-Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebc7c51e-5ab5-4799-866f-00391b41233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['f1024', 'f2048', 'f4096', 'slide_id', 'project', 'description'],\n",
       "    num_rows: 11664\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e932bf5e-85a0-4e7e-8bca-f204a61b72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (19/19 shards): 100%|██████████| 910/910 [00:04<00:00, 189.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 保存数据集\n",
    "dataset.save_to_disk('/bask/projects/p/phwq4930-renal-canc/Zeyu/WSI_Dataset')\n",
    "# 加载数据集\n",
    "loaded_dataset = Dataset.load_from_disk('/bask/projects/p/phwq4930-gbm/Zeyu/WSI_Dataset/WVLMdata_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc0d9924-6ce8-45b0-a6fb-efe4443c5bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['f1', 'cor1', 'f2', 'cor2', 'f3', 'cor3', 'label'],\n",
       "    num_rows: 910\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc437c3-1fd1-4c8e-b07a-3e77386c7c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bask/projects/p/phwq4930-gbm/Zeyu/asiw9691_conda_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# upload a sample dataset to huggingface\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08b0457-93b7-418d-8f91-1d57ad0a68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dirs = '/bask/projects/p/phwq4930-gbm/Zeyu/WSI_Dataset/TCGA-WSI-Text-Folds'\n",
    "dataset = load_from_disk(load_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab978131-d9e6-4ed8-8e27-cd8f4343fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[f'fold_9']\n",
    "# dataset.push_to_hub(\"CNX-PathLLM/TCGA-WSI-Text-Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e772a3ab-b677-4d1a-ae86-1b981a248fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['f1', 'cor1', 'f2', 'cor2', 'f3', 'cor3', 'label', 'slide_id', 'project'],\n",
       "    num_rows: 1247\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ce8bd-e449-4598-9fb7-ac0ca6b4cfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asiw9691_conda_env (Conda)",
   "language": "python",
   "name": "sys_asiw9691_conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
